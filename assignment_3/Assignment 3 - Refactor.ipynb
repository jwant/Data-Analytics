{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant Outliers for the Work Required\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import math\n",
    "import itertools as iter\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up datafram and test data\n",
    "df_test = pd.read_csv(r'test-pub.csv')\n",
    "df = pd.read_csv(r'train.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREPROCESSING ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code from Jun that turns all classifications into binaries\n",
    "# This will remove any unknown entries and assist with using the datas to our advantage\n",
    "df_onehot = pd.get_dummies(df)\n",
    "\n",
    "keys = df_onehot.keys()\n",
    "data_keys = [k for k in keys\n",
    "    if '?' not in k and k[-3:] != \"50K\"]\n",
    "data_train = df_onehot[data_keys]\n",
    "target_train = df_onehot[\"Salary_ >50K\"]\n",
    "\n",
    "df_onehot1 = pd.get_dummies(df_test)\n",
    "# add all zero to non-existing keys\n",
    "for k in data_keys:\n",
    "    if k not in df_onehot1.keys():\n",
    "        df_onehot1[k] = 0\n",
    "\n",
    "data_test = df_onehot1[data_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim Features Used in Testing\n",
    "data_train_features = [i for i in data_train.keys()]\n",
    "\n",
    "# Remove Final Weight and ID, they may be used at a later stage but are being ignored for training\n",
    "data_train_features.remove('ID')\n",
    "data_train_features.remove('Fnlwgt')\n",
    "\n",
    "# Since binarisation blows the native country category out we will be keeping only the American natives for training\n",
    "native_keys = [i for i in data_train.keys() if 'Native' in i]\n",
    "native_keys.remove('Native country_ United-States')\n",
    "data_train_features = [i for i in data_train_features if i not in native_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the descrete functions for data preprocessing for normalisation\n",
    "def normalize_values(dataframe):\n",
    "    max_abs_scalar = prep.MaxAbsScaler()\n",
    "    min_max_scalar = prep.MinMaxScaler()\n",
    "    standard_scalar = prep.StandardScaler()\n",
    "    robust_scalar = prep.RobustScaler()\n",
    "\n",
    "\n",
    "    col_names = ['Work hours per week','Age','Education years','Capital gain','Capital loss']\n",
    "\n",
    "    scaled_features = dataframe.copy()\n",
    "    features = scaled_features[col_names]\n",
    "    scaler = min_max_scalar.fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    dataframe[col_names] = features\n",
    "    return dataframe\n",
    "\n",
    "data_train = normalize_values(data_train)\n",
    "data_test = normalize_values(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train[data_train_features].describe()\n",
    "data_test[data_train_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Classification Class ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier():\n",
    "    features = []\n",
    "    clf = False\n",
    "    clf_model = False\n",
    "    setting_distributions = {}\n",
    "    tuned_settings = {}\n",
    "    train_data = False\n",
    "    train_target = False\n",
    "    validation_data = False\n",
    "    validation_target = False\n",
    "    best_roc_score = 0\n",
    "    best_output = False\n",
    "    \n",
    "    best_feature_scores = 0\n",
    "    best_features = []\n",
    "    \n",
    "    def __init__(self):\n",
    "  \n",
    "        self.features = data_train_features\n",
    "        \n",
    "        data = data_train[self.features]\n",
    "        sample_weight = data_train['Fnlwgt']\n",
    "        data_target = target_train\n",
    "        \n",
    "        n_training_samples = int(len(data) *.90)\n",
    "        n_validation_samples = len(data) - n_training_samples\n",
    "        self.train_data = data.head(n_training_samples)\n",
    "        self.train_target = data_target.head(n_training_samples)\n",
    "        self.train_weight = sample_weight.head(n_training_samples)\n",
    "        self.validation_data = data.tail(n_validation_samples)\n",
    "        self.validation_target = data_target.tail(n_validation_samples)\n",
    "\n",
    "        \n",
    "    def init_model(self,settings=False):\n",
    "        if not self.clf:\n",
    "            return\n",
    "        \n",
    "        if settings:\n",
    "            self.clf_model = self.clf(**settings)\n",
    "        else:\n",
    "            self.clf_model = self.clf()\n",
    "        \n",
    "    def train(self):\n",
    "        try:\n",
    "            self.clf_model.fit(X=self.train_data[self.features], y=self.train_target, sample_weight=self.train_weight)\n",
    "        except TypeError:\n",
    "            print('Sample Weight Ignored')\n",
    "            self.clf_model.fit(X=self.train_data[self.features], y=self.train_target)\n",
    "        \n",
    "    def validate(self):\n",
    "        validation_probabilities = self.clf_model.predict_proba(self.validation_data[self.features])[:,1]\n",
    "        score = roc_auc_score(y_true=self.validation_target, y_score=validation_probabilities)\n",
    "        \n",
    "        if score > self.best_roc_score:\n",
    "            self.best_roc_score = score\n",
    "            test_probabilities = self.clf_model.predict_proba(data_test[self.features])[:,1]\n",
    "            self.best_output = df_test.copy()\n",
    "            self.best_output['Predicted'] = test_probabilities\n",
    "            print('Score Improved')\n",
    "        return score\n",
    "    \n",
    "    def export(self, file_name, best=False):\n",
    "        if best:\n",
    "            output = self.best_output\n",
    "        else:\n",
    "            test_probabilities = self.clf_model.predict_proba(data_test[self.features])[:,1]\n",
    "            output = df_test.copy()\n",
    "            output['Predicted'] = test_probabilities\n",
    "            \n",
    "        output[[\"ID\",\"Predicted\"]].to_csv(file_name, index=False)\n",
    "        \n",
    "    def tune_settings(self):            \n",
    "        tuning_clf = RandomizedSearchCV(self.clf_model, self.setting_distributions, scoring='roc_auc')\n",
    "        search = tuning_clf.fit(X=self.train_data[self.features],y=self.train_target)\n",
    "        self.tuned_settings = search.best_params_\n",
    "        return self.tuned_settings\n",
    "    \n",
    "    def find_best_features(self, n_features):\n",
    "        status = 0\n",
    "        best_roc_auc_score = 0\n",
    "        features = [i for i in self.features if i not in self.best_features]\n",
    "        if len(features) < n_features:\n",
    "            n_combinations = 0\n",
    "        else:\n",
    "            n_combinations = math.factorial(len(features)) / math.factorial(n_features) / math.factorial(len(features)-n_features)\n",
    "\n",
    "        print('Combinations: ' + str(n_combinations))\n",
    "\n",
    "        for i in iter.combinations(features, r=n_features):\n",
    "            feats = list(i) + self.best_features\n",
    "            self.clf_model.fit(X=self.train_data[feats],y=self.train_target)\n",
    "            validation_probabilities = self.clf_model.predict_proba(self.validation_data[feats])[:,1]\n",
    "            score = roc_auc_score(y_true=self.validation_target, y_score=validation_probabilities)\n",
    "            if score > best_roc_auc_score:\n",
    "                best_roc_auc_score = score\n",
    "                best_key = i\n",
    "                print(str(best_key) + ' : ' + str(best_roc_auc_score))\n",
    "\n",
    "            status += 1\n",
    "            if status % 50 == 0:                \n",
    "                print('Completed ' + str(status) + ' of ' + str(n_combinations))\n",
    "\n",
    "\n",
    "        print(str(best_key) + '\\n' + str(best_roc_auc_score))\n",
    "        self.best_features += best_key\n",
    "        self.best_feature_scores = score\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model Training #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random Forest Classifier ####\n",
    "from sklearn.ensemble import RandomForestClassifier as rdmfrst\n",
    "rdm_frst_clf = classifier()\n",
    "rdm_frst_clf.clf = rdmfrst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_frst_clf.__init__() # reset data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validate\n",
    "rdm_frst_clf.init_model(settings=rdm_frst_clf.tuned_settings)\n",
    "rdm_frst_clf.train()\n",
    "rdm_frst_clf.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    score = rdm_frst_clf.find_best_features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_frst_clf.features = rdm_frst_clf.best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Settings\n",
    "rdm_frst_clf.setting_distributions = {\n",
    "    'n_estimators': list(range(0,2000,10)), # number of trees in the forest\n",
    "    'bootstrap': [True,False], # repeatably sample from training data\n",
    "    'oob_score': [True,False], # test with points not used in set\n",
    "    'criterion': ['gini', 'entropy'], # scored nodes\n",
    "    'max_depth': list(range(1,100)) + [None], # max depth of the tree\n",
    "    'max_features': ['auto', 'sqrt', 'log2'], # n features to make split discision\n",
    "}\n",
    "rdm_frst_clf.tune_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "rdm_frst_clf.export('rdm_frst_v5.csv', best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_feature_importance(keys,clf):\n",
    "    key_importance = []\n",
    "    for i in range(len(keys)):\n",
    "        key_importance += [(keys[i], clf.feature_importances_[i])]\n",
    "    return sorted(key_importance, key=lambda a: a[1], reverse=True)\n",
    "\n",
    "top_tree_features = [i[0] for i in return_feature_importance(rdm_frst_clf.features,rdm_frst_clf.clf_model)[:20]]\n",
    "top_tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Nearest Neighbour Classifier ####\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "knn_clf = classifier()\n",
    "knn_clf.clf = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.__init__() # reset data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validate\n",
    "knn_clf.init_model(settings=knn_clf.tuned_settings)\n",
    "knn_clf.train()\n",
    "knn_clf.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    score = knn_clf.find_best_features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.features = knn_clf.best_features\n",
    "knn_clf.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Settings\n",
    "knn_clf.setting_distributions = {\n",
    "    'n_neighbors': list(range(1,100,10)), # number of neighbours to use\n",
    "    'weights':['uniform', 'distance'], # neighbours are weighted uniformly or distance\n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], # algoirthm to determin neighbours\n",
    "    'p': [1,2], # 1: manhattan distance, 2: eclidian distance\n",
    "}\n",
    "knn_clf.tune_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "knn_clf.export('knn_v5.csv', best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression Classifier ####\n",
    "from sklearn.linear_model import LogisticRegression as log_reg\n",
    "log_reg_clf = classifier()\n",
    "log_reg_clf.clf = log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.__init__() # reset data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validate\n",
    "temp_settings = log_reg_clf.tuned_settings\n",
    "log_reg_clf.init_model(settings=temp_settings)\n",
    "\n",
    "log_reg_clf.train()\n",
    "log_reg_clf.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    score = log_reg_clf.find_best_features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.features = log_reg_clf.best_features\n",
    "# log_reg_clf.best_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune Settings\n",
    "log_reg_clf.setting_distributions = {\n",
    "    'solver':['lbfgs', 'liblinear'], # alogirthm used for optimization\n",
    "    'max_iter': list(range(0,6000,100)), # maximum iterations for the solver to converge\n",
    "    'fit_intercept': [True, False], # should a bias be applied to the desicion function\n",
    "}\n",
    "log_reg_clf.tune_settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "log_reg_clf.export('lr_v5.csv', best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adaboost Classifier ####\n",
    "from sklearn.ensemble import AdaBoostClassifier as ada_boost\n",
    "ada_boost_clf = classifier()\n",
    "ada_boost_clf.clf = ada_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_clf.__init__() # reset data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validate\n",
    "ada_boost_clf.init_model(settings=ada_boost_clf.tuned_settings)\n",
    "\n",
    "ada_boost_clf.train()\n",
    "ada_boost_clf.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Settings\n",
    "ada_boost_clf.setting_distributions = {\n",
    "    'n_estimators':list(range(1,1000)), # maximum number of estimators to boost\n",
    "    'learning_rate':list([0.0001,0.001,0.01,0.1,1]), # weight of each subsequent classifier\n",
    "}\n",
    "ada_boost_clf.tune_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada_boost_clf.best_features = []\n",
    "ada_boost_clf.features = ada_boost_clf.best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    score = ada_boost_clf.find_best_features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "ada_boost_clf.export('ada_boost_v1.csv', best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
